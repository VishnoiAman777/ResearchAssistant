# app.py
from dotenv import load_dotenv
import redis
import time
import os
import uuid
import traceback
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

_ = load_dotenv()
from agents.deep_agent import DeepAgents


app = FastAPI(title="Research Assistant Backend")

# === CONFIG ===
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))


# === ROBUST REDIS CONNECTION WITH RETRY ===
def get_redis_client():
    print(f"Connecting to Redis at {REDIS_HOST}:{REDIS_PORT}...")
    for attempt in range(15):
        try:
            client = redis.Redis(
                host=REDIS_HOST, port=REDIS_PORT, decode_responses=True, db=0
            )
            client.ping()
            print("Redis connected successfully!")
            return client
        except redis.ConnectionError as e:
            print(f"Redis not ready (attempt {attempt + 1}/15): {e}")
            time.sleep(3)
    raise Exception("Failed to connect to Redis after multiple attempts")


redis_client = get_redis_client()

# === THREAD POOL ===
executor = ThreadPoolExecutor(max_workers=10)

# === AGENT ===
deep_agent = DeepAgents()


# === PYDANTIC MODELS ===
class ChatRequest(BaseModel):
    """
    Request model for submitting a chat message to the research assistant.
    
    This Pydantic model defines the structure and validation for incoming chat requests
    to the /chat endpoint. It ensures that all required fields are provided and properly
    typed before processing by the deep agent.
    
    Attributes:
        message (str): The user's chat message or research query to be processed by the
                      research assistant agent.
        thread_id (str): A unique identifier for the conversation thread. This allows
                        the agent to maintain context across multiple exchanges within
                        the same conversation.
    """
    message: str
    thread_id: str


class TaskSubmitResponse(BaseModel):
    """
    Response model for chat task submission.
    
    This Pydantic model defines the structure of the response returned when a chat
    request is successfully submitted to the /chat endpoint. It provides the client
    with a task identifier for polling the status of the asynchronous request.
    
    Attributes:
        task_id (str): A unique identifier (UUID) assigned to the submitted task.
                      This ID is used by the client to poll the /status endpoint
                      for task progress and results.
        status (str): The initial status of the submitted task. Defaults to "pending"
                     to indicate the task has been queued but processing has not yet
                     begun. Other possible values include "processing" and "completed".
        message (str): A human-readable message providing context about the task
                      submission status, such as confirmation that the request is
                      being processed in the background.
    
    Note:
        This class was renamed to avoid conflicts with other modules in the codebase.
    """
    task_id: str
    status: str = "pending"
    message: str


class TaskStatusResponse(BaseModel):
    """
    Response model for task status queries.
    
    This Pydantic model defines the structure of the response returned by the /status
    endpoint. It provides comprehensive information about the current state of an
    asynchronous task, including any results or errors that may have occurred.
    
    Attributes:
        task_id (str): The unique identifier of the task being queried. This matches
                      the task_id returned from the original /chat submission.
        status (str): The current status of the task. Possible values include:
                     - "pending": Task has been submitted but not yet started
                     - "processing": Task is currently being processed by the agent
                     - "completed": Task has finished successfully
                     - "failed": Task encountered an error during processing
        result (str | None): The output/response from the research assistant agent if
                            the task completed successfully. None if the task is still
                            processing or if it failed. Contains the final message
                            content generated by the deep agent.
        error (str | None): A detailed error message if the task failed, including the
                           exception message and full traceback. None if the task is
                           still processing or completed successfully.
    """
    task_id: str
    status: str
    result: str | None = None
    error: str | None = None


# === BACKGROUND TASK ===
def process_chat_task(task_id: str, message: str, thread_id: str):
    try:
        redis_client.hset(f"task:{task_id}", mapping={"status": "processing"})
        print(f"Task {task_id} started processing: {message[:50]}...")

        result = deep_agent.invoke(message, thread_id=thread_id)
        print("==" * 100)
        print(result)
        print("==" * 100)
        response_content = result["messages"][-1].content

        redis_client.hset(
            f"task:{task_id}",
            mapping={"status": "completed", "result": response_content},
        )
        redis_client.expire(f"task:{task_id}", 3600)
        print(f"Task {task_id} completed successfully")

    except Exception as e:
        error_detail = f"{str(e)}\n{traceback.format_exc()}"
        print(f"Task {task_id} failed: {error_detail}")
        redis_client.hset(
            f"task:{task_id}", mapping={"status": "failed", "error": error_detail}
        )
        redis_client.expire(f"task:{task_id}", 3600)


# === ENDPOINTS ===
@app.post("/chat", response_model=TaskSubmitResponse)
async def chat_endpoint(request: ChatRequest):
    task_id = str(uuid.uuid4())

    redis_client.hset(
        f"task:{task_id}",
        mapping={
            "status": "pending",
            "message": request.message,
            "thread_id": request.thread_id,
        },
    )
    redis_client.expire(f"task:{task_id}", 3600)

    executor.submit(process_chat_task, task_id, request.message, request.thread_id)

    return TaskSubmitResponse(
        task_id=task_id, message="Your request is being processed in the background..."
    )


@app.get("/status/{task_id}", response_model=TaskStatusResponse)
def get_task_status(task_id: str):
    key = f"task:{task_id}"
    if not redis_client.exists(key):
        raise HTTPException(status_code=404, detail="Task not found or expired")

    data = redis_client.hgetall(key)

    return TaskStatusResponse(
        task_id=task_id,
        status=data.get("status", "unknown"),
        result=data.get("result"),
        error=data.get("error"),
    )


@app.get("/")
def health_check():
    return {"status": "ok", "message": "Research Assistant backend is running"}


@app.on_event("shutdown")
def shutdown_event():
    print("Shutting down thread pool...")
    executor.shutdown(wait=True)
